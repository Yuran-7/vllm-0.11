# vLLM Tests ç›®å½•ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£ä»‹ç» vLLM æµ‹è¯•å¥—ä»¶çš„ç»„ç»‡ç»“æ„ã€è¿è¡Œæ–¹å¼ä»¥åŠå„ä¸ªæµ‹è¯•æ¨¡å—çš„åŠŸèƒ½è¯´æ˜ã€‚

---

## ç›®å½•
- [å¦‚ä½•è¿è¡Œæµ‹è¯•](#å¦‚ä½•è¿è¡Œæµ‹è¯•)
- [æµ‹è¯•æ–‡ä»¶çš„ä¸¤ç§å½¢å¼](#æµ‹è¯•æ–‡ä»¶çš„ä¸¤ç§å½¢å¼)
- [Tests ç›®å½•ç»“æ„](#tests-ç›®å½•ç»“æ„)
- [æµ‹è¯•åˆ†ç±»ä¸æ ‡è®°](#æµ‹è¯•åˆ†ç±»ä¸æ ‡è®°)
- [å¸¸ç”¨æµ‹è¯•å‘½ä»¤](#å¸¸ç”¨æµ‹è¯•å‘½ä»¤)

---

## å¦‚ä½•è¿è¡Œæµ‹è¯•

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ pytestï¼ˆæ¨èï¼‰

vLLM ä½¿ç”¨ pytest ä½œä¸ºæµ‹è¯•æ¡†æ¶ï¼Œæ‰€æœ‰æµ‹è¯•æ–‡ä»¶éƒ½å¯ä»¥é€šè¿‡ pytest è¿è¡Œã€‚

#### è¿è¡Œæ‰€æœ‰æµ‹è¯•
```bash
pytest tests/
```

#### è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
```bash
pytest tests/cuda/test_cuda_context.py
```

#### è¿è¡Œç‰¹å®šæµ‹è¯•ç±»æˆ–å‡½æ•°
```bash
# è¿è¡Œæµ‹è¯•ç±»
pytest tests/cuda/test_cuda_context.py::TestSetCudaContext

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/cuda/test_cuda_context.py::TestSetCudaContext::test_set_cuda_context_parametrized

# è¿è¡ŒåŒ¹é…æ¨¡å¼çš„æµ‹è¯•
pytest tests/ -k "cuda"
```

#### æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
```bash
# æ˜¾ç¤ºæ‰€æœ‰è¾“å‡º
pytest tests/cuda/test_cuda_context.py -v -s

# æ˜¾ç¤ºæµ‹è¯•è¦†ç›–ç‡
pytest tests/ --cov=vllm --cov-report=html
```

---

### æ–¹å¼äºŒï¼šç›´æ¥è¿è¡Œï¼ˆä»…é™åŒ…å« `__main__` çš„æµ‹è¯•æ–‡ä»¶ï¼‰

æœ‰äº›æµ‹è¯•æ–‡ä»¶åŒ…å« `if __name__ == "__main__":` å—ï¼Œå¯ä»¥ç›´æ¥ä½œä¸º Python è„šæœ¬è¿è¡Œã€‚

```bash
python tests/cuda/test_cuda_context.py
```

**ç¤ºä¾‹ä»£ç **ï¼š
```python
# tests/cuda/test_cuda_context.py

class TestSetCudaContext:
    def test_set_cuda_context_parametrized(self, device_input, expected_device_id):
        # æµ‹è¯•ä»£ç 
        pass

if __name__ == "__main__":
    pytest.main([__file__, "-v"])  # ç›´æ¥è¿è¡Œä¼šè°ƒç”¨ pytest
```

---

## æµ‹è¯•æ–‡ä»¶çš„ä¸¤ç§å½¢å¼

### å½¢å¼ä¸€ï¼šçº¯ pytest æµ‹è¯•æ–‡ä»¶ï¼ˆæ—  `__main__`ï¼‰

**ç‰¹ç‚¹**ï¼š
- åªèƒ½é€šè¿‡ `pytest` å‘½ä»¤è¿è¡Œ
- å¤§éƒ¨åˆ†æµ‹è¯•æ–‡ä»¶å±äºæ­¤ç±»
- éµå¾ª pytest æ ‡å‡†ç»“æ„

**ç¤ºä¾‹**ï¼š
```python
# tests/test_config.py
import pytest
from vllm.config import VllmConfig

def test_compile_config_repr_succeeds():
    config = VllmConfig()
    val = repr(config)
    assert 'VllmConfig' in val

class TestModelConfig:
    def test_model_config_creation(self):
        # æµ‹è¯•ä»£ç 
        pass
```

**è¿è¡Œæ–¹å¼**ï¼š
```bash
pytest tests/test_config.py
```

---

### å½¢å¼äºŒï¼šåŒ…å« `__main__` çš„æµ‹è¯•æ–‡ä»¶

**ç‰¹ç‚¹**ï¼š
- å¯ä»¥ç›´æ¥ä½œä¸º Python è„šæœ¬è¿è¡Œ
- ä¹Ÿå¯ä»¥é€šè¿‡ `pytest` è¿è¡Œ
- é€šå¸¸ç”¨äºè°ƒè¯•æˆ–ç‹¬ç«‹è¿è¡Œçš„æµ‹è¯•

**ç¤ºä¾‹**ï¼š
```python
# tests/cuda/test_cuda_context.py
import pytest

class TestSetCudaContext:
    @pytest.mark.skipif(not current_platform.is_cuda(),
                        reason="CUDA not available")
    def test_set_cuda_context_parametrized(self, device_input, expected_device_id):
        # æµ‹è¯•ä»£ç 
        pass

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

**è¿è¡Œæ–¹å¼**ï¼ˆä¸¤ç§æ–¹å¼ç­‰æ•ˆï¼‰ï¼š
```bash
# æ–¹å¼ 1: ä½¿ç”¨ pytestï¼ˆæ¨èï¼‰
pytest tests/cuda/test_cuda_context.py -v

# æ–¹å¼ 2: ç›´æ¥è¿è¡Œï¼ˆä»…é™åŒ…å« __main__ çš„æ–‡ä»¶ï¼‰
python tests/cuda/test_cuda_context.py
```

**åŒ…å« `__main__` çš„æµ‹è¯•æ–‡ä»¶ï¼ˆéƒ¨åˆ†åˆ—è¡¨ï¼‰**ï¼š
```
tests/cuda/test_cuda_context.py
tests/v1/e2e/test_min_tokens.py
tests/v1/kv_connector/nixl_integration/test_disagg_accuracy.py
tests/model_executor/test_weight_utils.py
tests/quantization/test_torchao.py
tests/kernels/test_flex_attention.py
tests/kernels/moe/test_flashinfer_moe.py
tests/kv_transfer/test_send_recv.py
tests/distributed/test_shm_buffer.py
tests/evals/gsm8k/gsm8k_eval.py
tests/compile/piecewise/test_toy_llama.py
```

**å¯¹æ¯”**ï¼š

| ç‰¹æ€§ | æ—  `__main__` | æœ‰ `__main__` |
|------|--------------|--------------|
| **æ•°é‡** | å¤§å¤šæ•°æµ‹è¯•æ–‡ä»¶ | å°‘æ•°æµ‹è¯•æ–‡ä»¶ |
| **è¿è¡Œæ–¹å¼** | åªèƒ½ç”¨ pytest | pytest æˆ–ç›´æ¥è¿è¡Œ |
| **ç”¨é€”** | æ ‡å‡†å•å…ƒæµ‹è¯• | è°ƒè¯•/ç‹¬ç«‹æµ‹è¯•/æ€§èƒ½æµ‹è¯• |
| **ç¤ºä¾‹** | `test_config.py` | `test_cuda_context.py` |

---

## Tests ç›®å½•ç»“æ„

### ğŸ“ æµ‹è¯•ç›®å½•æ ‘

```
tests/
â”œâ”€â”€ conftest.py                    # pytest å…¨å±€é…ç½®å’Œ fixtures
â”œâ”€â”€ utils.py                       # æµ‹è¯•å·¥å…·å‡½æ•°
â”œâ”€â”€ ci_envs.py                     # CI ç¯å¢ƒé…ç½®
â”‚
â”œâ”€â”€ basic_correctness/             # åŸºç¡€æ­£ç¡®æ€§æµ‹è¯•
â”‚   â””â”€â”€ test_basic_correctness.py  # vLLM vs HuggingFace è¾“å‡ºå¯¹æ¯”
â”‚
â”œâ”€â”€ models/                        # æ¨¡å‹æµ‹è¯•
â”‚   â”œâ”€â”€ language/                  # è¯­è¨€æ¨¡å‹
â”‚   â”œâ”€â”€ multimodal/                # å¤šæ¨¡æ€æ¨¡å‹ï¼ˆè§†è§‰ã€éŸ³é¢‘ï¼‰
â”‚   â”œâ”€â”€ quantization/              # é‡åŒ–æ¨¡å‹
â”‚   â”œâ”€â”€ test_registry.py           # æ¨¡å‹æ³¨å†Œè¡¨æµ‹è¯•
â”‚   â””â”€â”€ test_initialization.py     # æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•
â”‚
â”œâ”€â”€ kernels/                       # CUDA/Triton Kernel æµ‹è¯•
â”‚   â”œâ”€â”€ attention/                 # æ³¨æ„åŠ›å†…æ ¸
â”‚   â”œâ”€â”€ moe/                       # MoE å†…æ ¸
â”‚   â”œâ”€â”€ mamba/                     # Mamba/SSM å†…æ ¸
â”‚   â”œâ”€â”€ quantization/              # é‡åŒ–å†…æ ¸
â”‚   â”œâ”€â”€ test_flex_attention.py     # FlexAttention æµ‹è¯•
â”‚   â””â”€â”€ test_triton_flash_attention.py  # Triton Flash Attention
â”‚
â”œâ”€â”€ v1/                            # V1 å¼•æ“æµ‹è¯•
â”‚   â”œâ”€â”€ engine/                    # å¼•æ“æ ¸å¿ƒ
â”‚   â”œâ”€â”€ core/                      # è°ƒåº¦å™¨ã€KV Cache
â”‚   â”œâ”€â”€ e2e/                       # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ entrypoints/               # API å…¥å£æµ‹è¯•
â”‚   â”œâ”€â”€ kv_connector/              # KV ä¼ è¾“æµ‹è¯•
â”‚   â””â”€â”€ executor/                  # æ‰§è¡Œå™¨æµ‹è¯•
â”‚
â”œâ”€â”€ distributed/                   # åˆ†å¸ƒå¼æµ‹è¯•
â”‚   â”œâ”€â”€ test_shm_buffer.py         # å…±äº«å†…å­˜ç¼“å†²åŒº
â”‚   â”œâ”€â”€ test_same_node.py          # åŒèŠ‚ç‚¹é€šä¿¡
â”‚   â””â”€â”€ test_eplb_algo.py          # è´Ÿè½½å‡è¡¡ç®—æ³•
â”‚
â”œâ”€â”€ quantization/                  # é‡åŒ–æµ‹è¯•
â”‚   â”œâ”€â”€ test_torchao.py            # TorchAO é‡åŒ–
â”‚   â”œâ”€â”€ test_fp8.py                # FP8 é‡åŒ–
â”‚   â””â”€â”€ test_compressed_tensors.py # å‹ç¼©å¼ é‡
â”‚
â”œâ”€â”€ cuda/                          # CUDA åŠŸèƒ½æµ‹è¯•
â”‚   â””â”€â”€ test_cuda_context.py       # CUDA ä¸Šä¸‹æ–‡ç®¡ç†
â”‚
â”œâ”€â”€ entrypoints/                   # API å…¥å£ç‚¹æµ‹è¯•
â”‚   â”œâ”€â”€ openai/                    # OpenAI å…¼å®¹ API
â”‚   â””â”€â”€ test_cli.py                # å‘½ä»¤è¡Œæ¥å£
â”‚
â”œâ”€â”€ compile/                       # torch.compile æµ‹è¯•
â”‚   â””â”€â”€ piecewise/                 # Piecewise CUDA Graph
â”‚
â”œâ”€â”€ lora/                          # LoRA é€‚é…å™¨æµ‹è¯•
â”œâ”€â”€ tokenization/                  # Tokenization æµ‹è¯•
â”œâ”€â”€ multimodal/                    # å¤šæ¨¡æ€è¾“å…¥æµ‹è¯•
â”œâ”€â”€ samplers/                      # é‡‡æ ·å™¨æµ‹è¯•
â”œâ”€â”€ speculative_decoding/          # æ¨æµ‹è§£ç æµ‹è¯•
â”œâ”€â”€ kv_transfer/                   # KV Cache ä¼ è¾“æµ‹è¯•
â”œâ”€â”€ engine/                        # å¼•æ“æµ‹è¯•
â”œâ”€â”€ config/                        # é…ç½®æµ‹è¯•
â”œâ”€â”€ detokenizer/                   # å Tokenization æµ‹è¯•
â”œâ”€â”€ evals/                         # è¯„ä¼°æµ‹è¯•
â”‚   â””â”€â”€ gsm8k/                     # GSM8K æ•°å­¦è¯„ä¼°
â”œâ”€â”€ benchmarks/                    # åŸºå‡†æµ‹è¯•
â”œâ”€â”€ standalone_tests/              # ç‹¬ç«‹æµ‹è¯•
â”œâ”€â”€ plugins_tests/                 # æ’ä»¶æµ‹è¯•
â”œâ”€â”€ runai_model_streamer_test/     # RunAI æ¨¡å‹æµæµ‹è¯•
â”œâ”€â”€ reasoning/                     # æ¨ç†æµ‹è¯•
â”œâ”€â”€ tool_use/                      # å·¥å…·è°ƒç”¨æµ‹è¯•
â””â”€â”€ tpu/                           # TPU æµ‹è¯•
```

---

## è¯¦ç»†æ¨¡å—è¯´æ˜

### 1. **basic_correctness/** - åŸºç¡€æ­£ç¡®æ€§æµ‹è¯•

**ç›®çš„**ï¼šéªŒè¯ vLLM è¾“å‡ºä¸ HuggingFace Transformers çš„ä¸€è‡´æ€§

**å…³é”®æµ‹è¯•æ–‡ä»¶**ï¼š
- `test_basic_correctness.py`: å¯¹æ¯” vLLM å’Œ HF çš„ç”Ÿæˆè¾“å‡º

**ç¤ºä¾‹æµ‹è¯•**ï¼š
```python
def test_vllm_gc_ed():
    """éªŒè¯ vLLM å®ä¾‹è¢«æ­£ç¡®å›æ”¶"""
    llm = LLM("distilbert/distilgpt2")
    weak_llm = weakref.ref(llm)
    del llm
    assert weak_llm() is None
```

**è¿è¡Œ**ï¼š
```bash
pytest tests/basic_correctness/ -v
```

---

### 2. **models/** - æ¨¡å‹æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯•å„ç§æ¨¡å‹æ¶æ„çš„åŠ è½½ã€åˆå§‹åŒ–å’Œæ¨ç†

**å­ç›®å½•**ï¼š
- **language/**: çº¯è¯­è¨€æ¨¡å‹ï¼ˆLlama, GPT, Qwen ç­‰ï¼‰
- **multimodal/**: å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLLaVA, Qwen2-VL, InternVL ç­‰ï¼‰
- **quantization/**: é‡åŒ–æ¨¡å‹ï¼ˆAWQ, GPTQ, FP8 ç­‰ï¼‰

**å…³é”®æµ‹è¯•**ï¼š
- `test_registry.py`: æ¨¡å‹æ³¨å†Œè¡¨æµ‹è¯•
- `test_initialization.py`: æ¨¡å‹åˆå§‹åŒ–æµç¨‹æµ‹è¯•
- `test_transformers.py`: Transformers é›†æˆæµ‹è¯•

**ç¤ºä¾‹**ï¼š
```bash
# æµ‹è¯• Llama æ¨¡å‹
pytest tests/models/language/ -k "llama"

# æµ‹è¯•å¤šæ¨¡æ€æ¨¡å‹
pytest tests/models/multimodal/ -v
```

---

### 3. **kernels/** - CUDA/Triton Kernel æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯•åº•å±‚è®¡ç®—å†…æ ¸çš„æ­£ç¡®æ€§å’Œæ€§èƒ½

**å­ç›®å½•**ï¼š
- **attention/**: æ³¨æ„åŠ›æœºåˆ¶å†…æ ¸ï¼ˆFlash Attention, FlashInfer ç­‰ï¼‰
- **moe/**: MoEï¼ˆMixture of Expertsï¼‰å†…æ ¸
- **mamba/**: Mamba/State Space Models å†…æ ¸
- **quantization/**: é‡åŒ–å†…æ ¸ï¼ˆFP8, INT8 ç­‰ï¼‰

**å…³é”®æµ‹è¯•æ–‡ä»¶**ï¼š
- `test_flex_attention.py`: FlexAttention åç«¯æµ‹è¯•
- `test_triton_flash_attention.py`: Triton å®ç°çš„ Flash Attention
- `moe/test_flashinfer_moe.py`: FlashInfer MoE å†…æ ¸

**ç¤ºä¾‹**ï¼š
```bash
# æµ‹è¯• Flash Attention
pytest tests/kernels/test_flex_attention.py -v

# æµ‹è¯• MoE å†…æ ¸
pytest tests/kernels/moe/ -v
```

**æ³¨æ„**: è¿™äº›æµ‹è¯•éœ€è¦ç‰¹å®šçš„ GPU ç¡¬ä»¶ï¼ˆSM 8.0+ï¼‰

---

### 4. **v1/** - V1 å¼•æ“æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯• vLLM V1 å¼•æ“çš„å„ä¸ªç»„ä»¶

**å­ç›®å½•**ï¼š
- **engine/**: å¼•æ“æ ¸å¿ƒï¼ˆAsyncLLM, EngineCoreï¼‰
- **core/**: è°ƒåº¦å™¨ã€KV Cacheã€å†…å­˜ç®¡ç†
- **e2e/**: ç«¯åˆ°ç«¯æµ‹è¯•
- **entrypoints/**: API å…¥å£ç‚¹æµ‹è¯•
- **kv_connector/**: KV Cache ä¼ è¾“æµ‹è¯•ï¼ˆdisagg æ¶æ„ï¼‰
- **executor/**: æ¨¡å‹æ‰§è¡Œå™¨æµ‹è¯•

**å…³é”®æµ‹è¯•**ï¼š
- `test_async_llm_dp.py`: Data Parallel æµ‹è¯•
- `test_kv_sharing.py`: KV Cache å…±äº«æµ‹è¯•
- `e2e/test_min_tokens.py`: æœ€å° token ç”Ÿæˆæµ‹è¯•

**ç¤ºä¾‹**ï¼š
```bash
# æµ‹è¯• V1 å¼•æ“
pytest tests/v1/engine/ -v

# æµ‹è¯•ç«¯åˆ°ç«¯åœºæ™¯
pytest tests/v1/e2e/ -v
```

---

### 5. **distributed/** - åˆ†å¸ƒå¼æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯•å¤š GPU é€šä¿¡ã€å¼ é‡å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œ

**å…³é”®æµ‹è¯•æ–‡ä»¶**ï¼š
- `test_shm_buffer.py`: å…±äº«å†…å­˜ç¼“å†²åŒºæµ‹è¯•
- `test_shm_storage.py`: å…±äº«å†…å­˜å­˜å‚¨æµ‹è¯•
- `test_same_node.py`: åŒèŠ‚ç‚¹å¤š GPU é€šä¿¡
- `test_node_count.py`: èŠ‚ç‚¹è®¡æ•°æ£€æµ‹
- `test_eplb_algo.py`: Elastic Parallel Load Balancing ç®—æ³•

**ç¤ºä¾‹**ï¼š
```bash
# éœ€è¦å¤š GPU ç¯å¢ƒ
pytest tests/distributed/ -v

# æµ‹è¯•å…±äº«å†…å­˜
python tests/distributed/test_shm_buffer.py
```

---

### 6. **quantization/** - é‡åŒ–æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯•å„ç§é‡åŒ–æ–¹æ¡ˆçš„æ­£ç¡®æ€§

**æ”¯æŒçš„é‡åŒ–æ–¹æ³•**ï¼š
- AWQ (Activation-aware Weight Quantization)
- GPTQ (Generative Pre-trained Transformer Quantization)
- FP8 (8-bit Floating Point)
- Compressed Tensors
- TorchAO

**å…³é”®æµ‹è¯•æ–‡ä»¶**ï¼š
- `test_torchao.py`: TorchAO é‡åŒ–æ¡†æ¶
- `test_fp8.py`: FP8 é‡åŒ–
- `test_compressed_tensors.py`: å‹ç¼©å¼ é‡æ ¼å¼

**ç¤ºä¾‹**ï¼š
```bash
# æµ‹è¯• FP8 é‡åŒ–
pytest tests/quantization/test_fp8.py -v

# æµ‹è¯•æ‰€æœ‰é‡åŒ–æ–¹æ³•
pytest tests/quantization/ -v
```

---

### 7. **cuda/** - CUDA åŠŸèƒ½æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯• CUDA ç›¸å…³çš„åº•å±‚åŠŸèƒ½

**å…³é”®æµ‹è¯•**ï¼š
- `test_cuda_context.py`: CUDA ä¸Šä¸‹æ–‡ç®¡ç†å’Œå¤šçº¿ç¨‹éš”ç¦»

**ç¤ºä¾‹**ï¼š
```python
class TestSetCudaContext:
    @pytest.mark.skipif(not current_platform.is_cuda(),
                        reason="CUDA not available")
    def test_set_cuda_context_parametrized(self, device_input, expected_device_id):
        # æµ‹è¯•åœ¨éš”ç¦»çš„çº¿ç¨‹ä¸­è®¾ç½® CUDA ä¸Šä¸‹æ–‡
        pass
```

**è¿è¡Œ**ï¼š
```bash
pytest tests/cuda/ -v
# æˆ–
python tests/cuda/test_cuda_context.py
```

---

### 8. **entrypoints/** - API å…¥å£ç‚¹æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯•å„ç§ API å…¥å£ç‚¹çš„åŠŸèƒ½

**å­ç›®å½•**ï¼š
- **openai/**: OpenAI å…¼å®¹ API æµ‹è¯•
- **offline_mode/**: ç¦»çº¿æ¨¡å¼æµ‹è¯•
- **chat/**: èŠå¤©æ¥å£æµ‹è¯•

**ç¤ºä¾‹**ï¼š
```bash
# æµ‹è¯• OpenAI API
pytest tests/entrypoints/openai/ -v
```

---

### 9. **compile/** - torch.compile æµ‹è¯•

**ç›®çš„**ï¼šæµ‹è¯• PyTorch 2.x torch.compile åŠŸèƒ½

**å­ç›®å½•**ï¼š
- **piecewise/**: Piecewise CUDA Graph æµ‹è¯•

**å…³é”®æµ‹è¯•**ï¼š
- `test_toy_llama.py`: ç®€åŒ– Llama æ¨¡å‹çš„ç¼–è¯‘æµ‹è¯•

**ç¤ºä¾‹**ï¼š
```bash
pytest tests/compile/ -v
```

---

### 10. **å…¶ä»–é‡è¦ç›®å½•**

| ç›®å½• | åŠŸèƒ½ |
|------|------|
| **lora/** | LoRA é€‚é…å™¨åŠ è½½ã€åˆ‡æ¢ã€å¤š LoRA æ¨ç† |
| **tokenization/** | Tokenizer æ­£ç¡®æ€§ã€ç‰¹æ®Š token å¤„ç† |
| **multimodal/** | å¤šæ¨¡æ€è¾“å…¥å¤„ç†ï¼ˆå›¾ç‰‡ã€éŸ³é¢‘ã€è§†é¢‘ï¼‰ |
| **samplers/** | é‡‡æ ·ç®—æ³•æµ‹è¯•ï¼ˆtop-p, top-k, beam searchï¼‰ |
| **speculative_decoding/** | æ¨æµ‹è§£ç ï¼ˆMedusa, EAGLE ç­‰ï¼‰ |
| **kv_transfer/** | KV Cache ä¼ è¾“å’Œå…±äº« |
| **engine/** | å¼•æ“æ ¸å¿ƒç»„ä»¶ï¼ˆV0 å¼•æ“ï¼‰ |
| **config/** | é…ç½®ç³»ç»Ÿæµ‹è¯• |
| **detokenizer/** | å Tokenization æµ‹è¯• |
| **evals/** | æ¨¡å‹è¯„ä¼°ï¼ˆGSM8K, MMLU ç­‰ï¼‰ |
| **benchmarks/** | æ€§èƒ½åŸºå‡†æµ‹è¯• |
| **standalone_tests/** | ç‹¬ç«‹è¿è¡Œçš„æµ‹è¯• |
| **plugins_tests/** | æ’ä»¶ç³»ç»Ÿæµ‹è¯• |
| **tpu/** | TPU å¹³å°æµ‹è¯• |

---

## æµ‹è¯•åˆ†ç±»ä¸æ ‡è®°

vLLM ä½¿ç”¨ pytest markers æ¥åˆ†ç±»å’Œè¿‡æ»¤æµ‹è¯•ã€‚

### pytest æ ‡è®°å®šä¹‰

åœ¨ `pyproject.toml` ä¸­å®šä¹‰ï¼š

```toml
[tool.pytest.ini_options]
markers = [
    "slow_test",                    # æ…¢é€Ÿæµ‹è¯•ï¼ˆéœ€è¦é•¿æ—¶é—´è¿è¡Œï¼‰
    "skip_global_cleanup",          # è·³è¿‡å…¨å±€æ¸…ç†
    "core_model",                   # æ ¸å¿ƒæ¨¡å‹ï¼ˆæ¯ä¸ª PR éƒ½æµ‹è¯•ï¼‰
    "hybrid_model",                 # æ··åˆæ¨¡å‹ï¼ˆåŒ…å« Mamba å±‚ï¼‰
    "cpu_model",                    # CPU æµ‹è¯•
    "split",                        # åˆ†å‰²è¿è¡Œçš„æµ‹è¯•
    "distributed",                  # åˆ†å¸ƒå¼ GPU æµ‹è¯•
    "skip_v1",                      # ä¸åœ¨ V1 å¼•æ“ä¸Šè¿è¡Œ
    "optional",                     # å¯é€‰æµ‹è¯•ï¼ˆé»˜è®¤è·³è¿‡ï¼‰
]
```

### ä½¿ç”¨æ ‡è®°è¿‡æ»¤æµ‹è¯•

```bash
# åªè¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆæ’é™¤ slow_testï¼‰
pytest tests/ -m "not slow_test"

# åªè¿è¡Œæ ¸å¿ƒæ¨¡å‹æµ‹è¯•
pytest tests/models/ -m "core_model"

# åªè¿è¡Œåˆ†å¸ƒå¼æµ‹è¯•
pytest tests/ -m "distributed"

# è¿è¡Œå¯é€‰æµ‹è¯•
pytest tests/ --optional

# æ’é™¤ V1 å¼•æ“æµ‹è¯•
pytest tests/ -m "not skip_v1"
```

---

## å¸¸ç”¨æµ‹è¯•å‘½ä»¤

### åŸºç¡€å‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/

# è¿è¡Œç‰¹å®šç›®å½•
pytest tests/models/

# è¿è¡Œå•ä¸ªæ–‡ä»¶
pytest tests/cuda/test_cuda_context.py

# æ˜¾ç¤ºè¯¦ç»†è¾“å‡º
pytest tests/cuda/test_cuda_context.py -v -s

# åªæ˜¾ç¤ºå¤±è´¥çš„æµ‹è¯•
pytest tests/ -v --tb=short

# åœåœ¨ç¬¬ä¸€ä¸ªå¤±è´¥çš„æµ‹è¯•
pytest tests/ -x

# é‡æ–°è¿è¡Œå¤±è´¥çš„æµ‹è¯•
pytest tests/ --lf  # last-failed
```

---

### è¿‡æ»¤å’Œé€‰æ‹©æµ‹è¯•

```bash
# æŒ‰åç§°æ¨¡å¼åŒ¹é…
pytest tests/ -k "cuda"
pytest tests/ -k "test_set_cuda_context"

# æŒ‰æ ‡è®°è¿‡æ»¤
pytest tests/ -m "not slow_test"
pytest tests/ -m "core_model or cpu_model"

# è¿è¡Œç‰¹å®šæµ‹è¯•å‡½æ•°
pytest tests/cuda/test_cuda_context.py::TestSetCudaContext::test_set_cuda_context_parametrized
```

---

### å¹¶è¡Œè¿è¡Œæµ‹è¯•

```bash
# å®‰è£… pytest-xdist
pip install pytest-xdist

# ä½¿ç”¨å¤šæ ¸å¹¶è¡Œè¿è¡Œ
pytest tests/ -n auto  # è‡ªåŠ¨æ£€æµ‹ CPU æ ¸å¿ƒæ•°
pytest tests/ -n 4     # ä½¿ç”¨ 4 ä¸ªè¿›ç¨‹
```

---

### æµ‹è¯•è¦†ç›–ç‡

```bash
# å®‰è£… pytest-cov
pip install pytest-cov

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=vllm --cov-report=html

# åœ¨ç»ˆç«¯æ˜¾ç¤ºè¦†ç›–ç‡
pytest tests/ --cov=vllm --cov-report=term-missing
```

---

### è°ƒè¯•æµ‹è¯•

```bash
# æ˜¾ç¤ºå®Œæ•´çš„å †æ ˆè·Ÿè¸ª
pytest tests/cuda/test_cuda_context.py -vv --tb=long

# è¿›å…¥å¤±è´¥æµ‹è¯•çš„ pdb è°ƒè¯•å™¨
pytest tests/cuda/test_cuda_context.py --pdb

# æ˜¾ç¤ºæ‰€æœ‰ print è¾“å‡º
pytest tests/cuda/test_cuda_context.py -s

# æ˜¾ç¤º fixture ä½¿ç”¨æƒ…å†µ
pytest tests/ --fixtures
```

---

### GPU æµ‹è¯•

```bash
# æŒ‡å®š GPU
CUDA_VISIBLE_DEVICES=0 pytest tests/cuda/

# å¤š GPU æµ‹è¯•
CUDA_VISIBLE_DEVICES=0,1 pytest tests/distributed/ -m "distributed"

# è·³è¿‡éœ€è¦å¤š GPU çš„æµ‹è¯•
pytest tests/ -m "not distributed"
```

---

### CI ç¯å¢ƒæµ‹è¯•

```bash
# è®¾ç½®ç›®æ ‡æµ‹è¯•å¥—ä»¶
TARGET_TEST_SUITE=L4 pytest tests/

# è·³è¿‡æ…¢é€Ÿæµ‹è¯•
pytest tests/ -m "not slow_test"

# åªè¿è¡Œæ ¸å¿ƒæ¨¡å‹æµ‹è¯•
pytest tests/models/ -m "core_model"
```

---

## å¸¸è§é—®é¢˜

### 1. æµ‹è¯•å¤±è´¥ï¼šCUDA out of memory

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°‘å¹¶è¡Œåº¦
pytest tests/ -n 1

# è¿è¡Œå•ä¸ªæµ‹è¯•
pytest tests/cuda/test_cuda_context.py

# æ¸…ç† GPU ç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()"
```

---

### 2. æµ‹è¯•è·³è¿‡ï¼šç¼ºå°‘ä¾èµ–

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev]"

# å®‰è£…æµ‹è¯•ä¾èµ–
pip install pytest pytest-asyncio pytest-xdist pytest-cov
```

---

### 3. è¿è¡Œæ…¢é€Ÿæµ‹è¯•

```bash
# åªè¿è¡Œæ…¢é€Ÿæµ‹è¯•
pytest tests/ -m "slow_test" -v

# è®¾ç½®è¶…æ—¶æ—¶é—´
pytest tests/ --timeout=300  # 5 åˆ†é’Ÿè¶…æ—¶
```

---

### 4. æŸ¥çœ‹æµ‹è¯•æ”¶é›†ä¿¡æ¯

```bash
# æ˜¾ç¤ºæ‰€æœ‰æµ‹è¯•ä½†ä¸è¿è¡Œ
pytest tests/ --collect-only

# æ˜¾ç¤ºæµ‹è¯•ç»Ÿè®¡
pytest tests/ --fixtures
```

---

## conftest.py æ–‡ä»¶

`tests/conftest.py` åŒ…å«å…¨å±€ pytest é…ç½®å’Œ fixturesã€‚

**å…³é”® fixtures**ï¼š
- `vllm_runner`: åˆ›å»º vLLM å®ä¾‹
- `hf_runner`: åˆ›å»º HuggingFace æ¨¡å‹å®ä¾‹
- `example_prompts`: æµ‹è¯•æç¤ºè¯
- `image_assets`: å›¾ç‰‡æµ‹è¯•èµ„æº
- `audio_assets`: éŸ³é¢‘æµ‹è¯•èµ„æº

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
def test_basic_generation(vllm_runner):
    """ä½¿ç”¨ vllm_runner fixture"""
    with vllm_runner("meta-llama/Llama-2-7b-hf") as llm:
        outputs = llm.generate(["Hello"], sampling_params)
        assert len(outputs) == 1
```

---

## æœ€ä½³å®è·µ

### 1. ç¼–å†™æ–°æµ‹è¯•

```python
import pytest
from vllm import LLM

class TestMyFeature:
    """æµ‹è¯•ç±»åº”è¯¥ç”¨ Test å‰ç¼€"""
    
    @pytest.mark.skipif(not torch.cuda.is_available(),
                        reason="CUDA not available")
    def test_basic_functionality(self):
        """æµ‹è¯•å‡½æ•°ç”¨ test_ å‰ç¼€"""
        llm = LLM("facebook/opt-125m")
        outputs = llm.generate(["Hello"])
        assert len(outputs) == 1
    
    @pytest.mark.parametrize("model", [
        "facebook/opt-125m",
        "facebook/opt-350m",
    ])
    def test_multiple_models(self, model):
        """ä½¿ç”¨å‚æ•°åŒ–æµ‹è¯•å¤šä¸ªåœºæ™¯"""
        llm = LLM(model)
        assert llm.llm_engine is not None
```

---

### 2. ä½¿ç”¨ fixtures

```python
@pytest.fixture
def sample_llm():
    """åˆ›å»ºå¯é‡ç”¨çš„ fixture"""
    llm = LLM("facebook/opt-125m")
    yield llm
    del llm  # æ¸…ç†èµ„æº

def test_with_fixture(sample_llm):
    outputs = sample_llm.generate(["Hello"])
    assert len(outputs) == 1
```

---

### 3. æ·»åŠ æµ‹è¯•æ ‡è®°

```python
@pytest.mark.slow_test
def test_large_model():
    """æ ‡è®°æ…¢é€Ÿæµ‹è¯•"""
    pass

@pytest.mark.distributed
def test_multi_gpu():
    """æ ‡è®°åˆ†å¸ƒå¼æµ‹è¯•"""
    pass
```

---

## å‚è€ƒèµ„æ–™

| èµ„æº | è¯´æ˜ |
|------|------|
| **pytest æ–‡æ¡£** | https://docs.pytest.org/ |
| **vLLM å®˜æ–¹æ–‡æ¡£** | https://docs.vllm.ai/ |
| **CI é…ç½®** | `.github/workflows/` ç›®å½• |
| **æµ‹è¯•é…ç½®** | `pyproject.toml` `[tool.pytest.ini_options]` |

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æ›´æ–°æ—¥æœŸ**: 2026 å¹´ 2 æœˆ 14 æ—¥  
**é€‚ç”¨ vLLM ç‰ˆæœ¬**: 0.11.0+  
**ç»´æŠ¤è€…**: vLLM Community
